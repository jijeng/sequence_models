{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train =read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test =read_csv('data/tesss.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (132,), Y_train shape(132,)\n",
      "X_test shape (56,), Y_test shape(56,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 2, 3, 0, 4, 0, 3, 2, 3, 1, 3, 3, 1, 3, 2, 3, 2, 3, 1, 2, 3, 0,\n",
       "       2, 2, 2, 1, 4, 2, 2, 4, 0, 3, 4, 2, 0, 3, 2, 2, 3, 4, 2, 2, 0, 2,\n",
       "       3, 0, 3, 2, 4, 3, 0, 3, 3, 3, 4, 2, 1, 1, 1, 2, 3, 1, 0, 0, 0, 3,\n",
       "       4, 4, 2, 2, 1, 2, 0, 3, 2, 2, 0, 0, 3, 1, 2, 1, 2, 2, 4, 3, 3, 2,\n",
       "       4, 0, 0, 0, 3, 3, 3, 2, 0, 1, 2, 3, 0, 2, 2, 2, 3, 2, 2, 2, 4, 1,\n",
       "       1, 3, 3, 4, 1, 2, 1, 1, 3, 1, 0, 4, 0, 3, 3, 4, 4, 1, 4, 3, 0, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"X_train shape {}, Y_train shape{}\".format(X_train.shape, Y_train.shape))\n",
    "\n",
    "print(\"X_test shape {}, Y_test shape{}\".format(X_test.shape, Y_test.shape))\n",
    "y_train_back =Y_train\n",
    "y_train_back.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the max-len sentence in the whole txt(.csv)\n",
    "maxLen =len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lol'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python is so powerful, meaning is so powerful that hard to interpretate\n",
    "# the sentences below is the max-len sentence\n",
    "max(X_train, key=len)\n",
    "#min(X_train, key =len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'so',\n",
       " 'impressed',\n",
       " 'by',\n",
       " 'your',\n",
       " 'dedication',\n",
       " 'to',\n",
       " 'this',\n",
       " 'project']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default: use \" \" to split\n",
    "max(X_train, key =len).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miss you so much ❤️\n"
     ]
    }
   ],
   "source": [
    "index =3\n",
    "print(X_train[index], label_to_emoji(Y_train[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train =convert_to_one_hot(Y_train, C=5)\n",
    "Y_oh_train =convert_to_one_hot(Y_test, C =5)\n",
    "# implement the convert_to_one_hot is not so hard, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index =50\n",
    "print(Y_train[index], 'is converted into one hot',Y_oh_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing Emojifier\n",
    "word_to_index, index_to_word, word_to_vec_map =read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word ='cucumber'\n",
    "index =289846\n",
    "print(\"the index of \", wordf, \"in the vocabulary is \", word_to_index[word])\n",
    "print(\"the \", str(index)+\" th word in the vocabulary is\",index_to_word[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function: sentence_to_avg\n",
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    converts a sentence(string) into a list of words(string). \n",
    "    converts every sentence to lower-case, then split the sentence into a list of words\n",
    "    for each word in the sentence, access its Glove representation, then average all thses values\n",
    "    \"\"\"\n",
    "    words =sentence.lower().split()\n",
    "    avg =np.zeros(word_to_vec_map[words[0]].shape)\n",
    "    \n",
    "    for w in words:\n",
    "        avg += word_to_vec_map[w]\n",
    "    avg =avg/len(words)\n",
    "    return avg\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the sentence_to_avg function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function :model\n",
    "def model(X, Y, word_to_vec_map, learning_rate =0.01, num_iterations =400):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
